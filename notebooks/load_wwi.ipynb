{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54a8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b81781",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "initialLoadDate = datetime(2012, 12, 31, 0, 0, 0)\n",
    "initialLoad = initialLoadDate.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6b083e",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "newCutoff = \"\"\n",
    "fromNotebook = True\n",
    "source = \"\"\n",
    "destination = \"\"\n",
    "tables = \"\"\n",
    "sparkMaster = \"local[*]\"\n",
    "retriesMax = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501c72cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jars ../resources/jars/mssql-jdbc-13.2.0.jre11.jar\n",
      "source {'database': 'WideWorldImporters', 'url': 'jdbc:sqlserver://localhost\\\\MSSQLSERVER05;database=WideWorldImporters;user=sa;password=P@$$w0rd;encrypt=false'}\n",
      "desstination {'database': 'WideWorldImportersDW', 'url': 'jdbc:sqlserver://localhost\\\\MSSQLSERVER05;database=WideWorldImportersDW;user=sa;password=P@$$w0rd;encrypt=false'}\n",
      "tables [{'source': {'schema': 'Application', 'table': 'Cities', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_Cities'}}, {'source': {'schema': 'Application', 'table': 'Cities_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_Cities_Archive'}}, {'source': {'schema': 'Application', 'table': 'Countries', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_Countries'}}, {'source': {'schema': 'Application', 'table': 'Countries_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_Countries_Archive'}}, {'source': {'schema': 'Application', 'table': 'DeliveryMethods', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_DeliveryMethods'}}, {'source': {'schema': 'Application', 'table': 'DeliveryMethods_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_DeliveryMethods_Archive'}}, {'source': {'schema': 'Application', 'table': 'PaymentMethods', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_PaymentMethods'}}, {'source': {'schema': 'Application', 'table': 'PaymentMethods_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_PaymentMethods_Archive'}}, {'source': {'schema': 'Application', 'table': 'People', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_People'}}, {'source': {'schema': 'Application', 'table': 'People_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_People_Archive'}}, {'source': {'schema': 'Application', 'table': 'StateProvinces', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_StateProvinces'}}, {'source': {'schema': 'Application', 'table': 'StateProvinces_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_StateProvinces_Archive'}}, {'source': {'schema': 'Application', 'table': 'TransactionTypes', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_TransactionTypes'}}, {'source': {'schema': 'Application', 'table': 'TransactionTypes_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Application_TransactionTypes_Archive'}}, {'source': {'schema': 'Purchasing', 'table': 'PurchaseOrderLines', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Purchasing_PurchaseOrderLines'}}, {'source': {'schema': 'Purchasing', 'table': 'PurchaseOrders', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Purchasing_PurchaseOrders'}}, {'source': {'schema': 'Purchasing', 'table': 'SupplierCategories', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Purchasing_SupplierCategories'}}, {'source': {'schema': 'Purchasing', 'table': 'SupplierCategories_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Purchasing_SupplierCategories_Archive'}}, {'source': {'schema': 'Purchasing', 'table': 'Suppliers', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Purchasing_Suppliers'}}, {'source': {'schema': 'Purchasing', 'table': 'Suppliers_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Purchasing_Suppliers_Archive'}}, {'source': {'schema': 'Purchasing', 'table': 'SupplierTransactions', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Purchasing_SupplierTransactions'}}, {'source': {'schema': 'Sales', 'table': 'BuyingGroups', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Sales_BuyingGroups'}}, {'source': {'schema': 'Sales', 'table': 'BuyingGroups_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Sales_BuyingGroups_Archive'}}, {'source': {'schema': 'Sales', 'table': 'CustomerCategories', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Sales_CustomerCategories'}}, {'source': {'schema': 'Sales', 'table': 'CustomerCategories_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Sales_CustomerCategories_Archive'}}, {'source': {'schema': 'Sales', 'table': 'Customers', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Sales_Customers'}}, {'source': {'schema': 'Sales', 'table': 'Customers_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Sales_Customers_Archive'}}, {'source': {'schema': 'Sales', 'table': 'CustomerTransactions', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Sales_CustomerTransactions'}}, {'source': {'schema': 'Sales', 'table': 'InvoiceLines', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Sales_InvoiceLines'}}, {'source': {'schema': 'Sales', 'table': 'Invoices', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Sales_Invoices'}}, {'source': {'schema': 'Sales', 'table': 'OrderLines', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Sales_OrderLines'}}, {'source': {'schema': 'Sales', 'table': 'Orders', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Sales_Orders'}}, {'source': {'schema': 'Sales', 'table': 'SpecialDeals', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Sales_SpecialDeals'}}, {'source': {'schema': 'Warehouse', 'table': 'Colors', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_Colors'}}, {'source': {'schema': 'Warehouse', 'table': 'Colors_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_Colors_Archive'}}, {'source': {'schema': 'Warehouse', 'table': 'PackageTypes', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_PackageTypes'}}, {'source': {'schema': 'Warehouse', 'table': 'PackageTypes_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_PackageTypes_Archive'}}, {'source': {'schema': 'Warehouse', 'table': 'StockGroups', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_StockGroups'}}, {'source': {'schema': 'Warehouse', 'table': 'StockGroups_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_StockGroups_Archive'}}, {'source': {'schema': 'Warehouse', 'table': 'StockItemHoldings', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_StockItemHoldings'}}, {'source': {'schema': 'Warehouse', 'table': 'StockItems', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_StockItems'}}, {'source': {'schema': 'Warehouse', 'table': 'StockItems_Archive', 'type': 'ValidDateRange'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_StockItems_Archive'}}, {'source': {'schema': 'Warehouse', 'table': 'StockItemStockGroups', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_StockItemStockGroups'}}, {'source': {'schema': 'Warehouse', 'table': 'StockItemTransactions', 'type': 'LastEditedDate'}, 'destination': {'schema': 'dbo', 'table': 'Warehouse_StockItemTransactions'}}]\n"
     ]
    }
   ],
   "source": [
    "jars = \"\"\n",
    "\n",
    "if fromNotebook:\n",
    "    f = open('load_wwi.json',)\n",
    "    config = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    newCutoff = config[\"cutoff_date\"]\n",
    "    jars = \"../resources/jars/mssql-jdbc-13.2.0.jre11.jar\"\n",
    "    source = config[\"source\"]\n",
    "    destination = config[\"destination\"]\n",
    "    tables = config[\"tables\"]\n",
    "else:\n",
    "    jars = \"{0}/resources/jars/mssql-jdbc-13.2.0.jre11.jar\".format(path)\n",
    "\n",
    "print(\"jars\", jars)\n",
    "print(\"source\", source)\n",
    "print(\"desstination\", destination)\n",
    "print(\"tables\", tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447b1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session():\n",
    "    if fromNotebook:\n",
    "        return (\n",
    "            SparkSession.builder \n",
    "                .config(\n",
    "                    \"spark.driver.host\", \n",
    "                    \"localhost\"\n",
    "                )\n",
    "                .master(sparkMaster)\n",
    "                .appName(\"load_wwi\")\n",
    "                .config(\"spark.jars\", jars)    \n",
    "                .getOrCreate()\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            SparkSession.builder \n",
    "                .master(sparkMaster)\n",
    "                .appName(\"load_wwi\")\n",
    "                .config(\"spark.jars\", jars)\n",
    "                .config(\"spark.executor.memory\", \"4g\")\n",
    "                .config(\"spark.driver.memory\", \"4g\")\n",
    "                .config(\"spark.executor.cores\", \"6\")\n",
    "                .config(\"spark.cores.max\", \"6\")\n",
    "                .config(\"spark.network.timeout\", \"600s\")\n",
    "                .config(\"spark.executor.heartbeatInterval\", \"599s\")\n",
    "                .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b9cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_spark_session():\n",
    "    active_spark_session = SparkSession.getActiveSession()\n",
    "    \n",
    "    if active_spark_session:\n",
    "        active_spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3e68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_db_table(sourceDatabase, sourceSchema, sourceTable, sourceType, lastCutoff):\n",
    "    sourceDbTable = \"\"\n",
    "\n",
    "    if sourceType == 'ValidDateRange':\n",
    "        sourceDbTable = \"\"\"\n",
    "            (\n",
    "                SELECT \n",
    "                    *,\n",
    "                    [LoadDate] = CAST('@NewCutoff' AS DATETIME)\n",
    "                FROM \n",
    "                    @Database.@Schema.@Table \n",
    "                WHERE \n",
    "                    ValidFrom > '@LastCutoff' AND\t\n",
    "                    ValidFrom <= '@NewCutoff' \n",
    "            ) AS @Table\n",
    "        \"\"\"\n",
    "    else:\n",
    "        sourceDbTable = \"\"\"\n",
    "            (\n",
    "                SELECT \n",
    "                    *,\n",
    "                    [LoadDate] = CAST('@NewCutoff' AS DATETIME)\n",
    "                FROM \n",
    "                    @Database.@Schema.@Table \n",
    "                WHERE \n",
    "                    LastEditedWhen > '@LastCutoff' AND\n",
    "                    LastEditedWhen <= '@NewCutoff'\n",
    "            ) AS @Table\n",
    "        \"\"\"\n",
    "\n",
    "    sourceDbTable = sourceDbTable.replace(\n",
    "        \"@Database\", \n",
    "        sourceDatabase\n",
    "    ).replace(\n",
    "        \"@Schema\", \n",
    "        sourceSchema\n",
    "    ).replace(\n",
    "        \"@Table\",\n",
    "        sourceTable\n",
    "    ).replace(\n",
    "        \"@LastCutoff\",\n",
    "        lastCutoff\n",
    "    ).replace(\n",
    "        \"@NewCutoff\",\n",
    "        newCutoff\n",
    "    ).replace(\n",
    "        \"@InitialLoad\",\n",
    "        initialLoad\n",
    "    )\n",
    "\n",
    "    return sourceDbTable\n",
    "\n",
    "def load_wwi_to_wh(table, lastCutoff):\n",
    "    sourceDatabase = source[\"database\"]\n",
    "    sourceSchema = table[\"source\"][\"schema\"]\n",
    "    sourceTable = table[\"source\"][\"table\"]\n",
    "    sourceType = table[\"source\"][\"type\"]\n",
    "    sourceDbTable = get_source_db_table(\n",
    "        sourceDatabase,\n",
    "        sourceSchema,\n",
    "        sourceTable,\n",
    "        sourceType,\n",
    "        lastCutoff\n",
    "    )\n",
    "    \n",
    "    destDatabase = destination[\"database\"]\n",
    "    destSchema = table[\"destination\"][\"schema\"]\n",
    "    destTable = table[\"destination\"][\"table\"]\n",
    "    destDbTable = \"{0}.{1}.{2}\".format(destDatabase, destSchema, destTable)\n",
    "\n",
    "    retries = 0\n",
    "    isSuccessful = False\n",
    "\n",
    "    while retries < retriesMax:\n",
    "        retries = retries + 1\n",
    "\n",
    "        try:\n",
    "            \n",
    "            spark = get_spark_session()\n",
    "            \n",
    "            # delete \n",
    "            if (retries - 1) > 0:\n",
    "                delete_duplicates(table)\n",
    "\n",
    "            # read \n",
    "            df = (\n",
    "                spark.read\n",
    "                    .format(\"jdbc\")\n",
    "                    .option(\"url\", source[\"url\"])\n",
    "                    .option(\"dbtable\", sourceDbTable)\n",
    "                    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
    "                    .load()\n",
    "            )\n",
    "            \n",
    "            # write\n",
    "            (\n",
    "                df.write\n",
    "                    .format(\"jdbc\")\n",
    "                    .mode(\"append\")\n",
    "                    .option(\"url\", destination[\"url\"])\n",
    "                    .option(\"dbtable\", destDbTable)\n",
    "                    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
    "                    .save()\n",
    "            )\n",
    "\n",
    "            retries = retriesMax\n",
    "\n",
    "            isSuccessful = True\n",
    "\n",
    "        except Exception as ex:\n",
    "            stop_spark_session()\n",
    "\n",
    "            if retries >= retriesMax:\n",
    "                raise ex\n",
    "\n",
    "    if isSuccessful == False:\n",
    "        raise Exception(\"Unable to load table to warehouse\")\n",
    "    else:\n",
    "        # save success load history\n",
    "        insert_load_history(table, 'Successful')\n",
    "\n",
    "def delete_duplicates(table):\n",
    "    destDatabase = destination[\"database\"]\n",
    "    destSchema = table[\"destination\"][\"schema\"]\n",
    "    destTable = table[\"destination\"][\"table\"]\n",
    "    destDbTable = \"{0}.{1}.{2}\".format(destDatabase, destSchema, destTable)\n",
    "\n",
    "    retries = 0\n",
    "    isSuccessful = False\n",
    "\n",
    "    while retries < retriesMax:    \n",
    "        \n",
    "        retries = retries + 1\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            spark = get_spark_session()\n",
    "\n",
    "            connection = spark._jvm.java.sql.DriverManager.getConnection(destination[\"url\"])\n",
    "            \n",
    "            statement = connection.createStatement()\n",
    "            \n",
    "            result = statement.executeQuery(\"\"\"\n",
    "                SELECT row_count = COUNT(*)\n",
    "                FROM INFORMATION_SCHEMA.TABLES\n",
    "                WHERE TABLE_CATALOG = '{0}' AND TABLE_SCHEMA = '{1}' AND TABLE_NAME = '{2}'\n",
    "            \"\"\".format(destDatabase, destSchema, destTable))\n",
    "            \n",
    "            result.next()\n",
    "\n",
    "            if result.getInt(\"row_count\") > 0:\n",
    "                statement.executeUpdate(\"DELETE {0} WHERE LoadDate = '{1}'\".format(destDbTable, newCutoff))\n",
    "\n",
    "            retries = retriesMax\n",
    "    \n",
    "            isSuccessful = True\n",
    "\n",
    "        except Exception as ex:\n",
    "            stop_spark_session()\n",
    "\n",
    "            if retries >= retriesMax:\n",
    "                raise ex\n",
    "\n",
    "    if isSuccessful == False:\n",
    "        raise Exception(\"Unable to delete duplicates\")\n",
    "    \n",
    "def insert_load_history(table, status):\n",
    "    destTable = table[\"destination\"][\"table\"]\n",
    "\n",
    "    retries = 0\n",
    "    isSuccessful = False\n",
    "\n",
    "    while retries < retriesMax:\n",
    "        \n",
    "        retries = retries + 1\n",
    "        \n",
    "        try:\n",
    "            spark = get_spark_session()\n",
    "\n",
    "            df = (\n",
    "                spark.read\n",
    "                    .format(\"jdbc\")\n",
    "                    .option(\"url\", destination[\"url\"])\n",
    "                    .option(\"dbtable\", \"\"\"\n",
    "                        (\n",
    "                            SELECT\n",
    "                                TableName,\n",
    "                                LoadDate,\n",
    "                                Status,\n",
    "                                Details\n",
    "                            FROM \n",
    "                                LoadHistory\n",
    "                            WHERE\n",
    "                                1 <> 1\n",
    "                            \n",
    "                            UNION\n",
    "\n",
    "                            SELECT\n",
    "                                [TableName] = '@TableName',\n",
    "                                [LoadDate] = '@LoadDate',\n",
    "                                [Status] = '@Status',\n",
    "                                [Deatils] = NULL \n",
    "                        ) AS LoadHistory\n",
    "                    \"\"\".replace(\n",
    "                        \"@TableName\", \n",
    "                        destTable\n",
    "                    ).replace(\n",
    "                        \"@LoadDate\", \n",
    "                        newCutoff\n",
    "                    ).replace(\n",
    "                        \"@Status\", \n",
    "                        status\n",
    "                    )\n",
    "                )\n",
    "                .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
    "                .load()\n",
    "            )\n",
    "                \n",
    "            # write\n",
    "            (\n",
    "                df.write\n",
    "                    .format(\"jdbc\")\n",
    "                    .mode(\"append\")\n",
    "                    .option(\"url\", destination[\"url\"])\n",
    "                    .option(\"dbtable\", \"LoadHistory\")\n",
    "                    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
    "                    .save()\n",
    "            )\n",
    "\n",
    "            retries = retriesMax\n",
    "\n",
    "            isSuccessful = True\n",
    "\n",
    "        except Exception as ex:            \n",
    "            stop_spark_session()\n",
    "\n",
    "            if retries >= retriesMax:\n",
    "                raise ex\n",
    "\n",
    "    if isSuccessful == False:\n",
    "        raise Exception(\"Unable to insert load history\")\n",
    "\n",
    "def set_lastcutoff_date(table, initialLoadDate):\n",
    "    destTable = table[\"destination\"][\"table\"]\n",
    "    lastCutoffDate = initialLoadDate\n",
    "    \n",
    "    loadHistoryTable = \"\"\"\n",
    "        (\n",
    "            SELECT TOP 1\n",
    "                * \n",
    "            FROM \n",
    "                LoadHistory \n",
    "            WHERE \n",
    "                TableName LIKE '@TableName' AND\n",
    "                Status = 'Successful'\n",
    "            ORDER BY\n",
    "                LoadDate DESC\n",
    "        ) AS LoadHistory\n",
    "    \"\"\".replace(\n",
    "        \"@TableName\", \n",
    "        destTable\n",
    "    ).replace(\n",
    "        \"@CutoffDate\", \n",
    "        newCutoff\n",
    "    )\n",
    "\n",
    "    retries = 0\n",
    "    isSuccessful = False\n",
    "\n",
    "    while retries < retriesMax:\n",
    "\n",
    "        try:\n",
    "            \n",
    "            spark = get_spark_session()\n",
    "\n",
    "            # read \n",
    "            df = (\n",
    "                spark.read\n",
    "                    .format(\"jdbc\")\n",
    "                    .option(\"url\", destination[\"url\"])\n",
    "                    .option(\"dbtable\", loadHistoryTable)\n",
    "                    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n",
    "                    .load()\n",
    "            )\n",
    "\n",
    "            if df.count() > 0:\n",
    "                lastCutoffDate = df.collect()[0][\"LoadDate\"]\n",
    "\n",
    "            retries = retriesMax\n",
    "\n",
    "            isSuccessful = True\n",
    "            \n",
    "        except Exception as ex:\n",
    "            stop_spark_session()\n",
    "\n",
    "            if retries >= retriesMax:\n",
    "                raise ex\n",
    "\n",
    "    if isSuccessful == False:\n",
    "        raise Exception(\"Unable to set lastcutoff date\")\n",
    "    \n",
    "    return lastCutoffDate.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "for table in tables:\n",
    "    lastCutoff = set_lastcutoff_date(table, initialLoadDate)\n",
    "\n",
    "    if datetime.strptime(newCutoff, \"%Y-%m-%d %H:%M:%S\") > datetime.strptime(lastCutoff, \"%Y-%m-%d %H:%M:%S\"):\n",
    "        load_wwi_to_wh(\n",
    "            table,\n",
    "            lastCutoff\n",
    "        )\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
